\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{multirow}

\geometry{margin=2.5cm}

% Code listing style
\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    stringstyle=\color{red},
    commentstyle=\color{green!60!black},
    numbers=left,
    numberstyle=\tiny\color{gray},
    stepnumber=1,
    numbersep=5pt,
    backgroundcolor=\color{gray!10},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    frame=single,
    rulecolor=\color{black},
    tabsize=2,
    captionpos=b,
    breaklines=true,
    breakatwhitespace=false,
    escapeinside={\%*}{*)}
}

\title{\textbf{Real-Time Object Detection System using YOLO and GPU Acceleration}\\
\large Fine-Tuning for Specific Car Recognition}
\author{Omar Mejri \and [Partner Name]}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This report presents the development of a real-time object detection system using YOLO (You Only Look Once) and NVIDIA GPU acceleration. Initially designed as a general object detection system, the project evolved into a fine-tuned model capable of recognizing a specific car among many vehicles. The system leverages CUDA-enabled PyTorch for GPU acceleration, Label Studio for data annotation, and YOLOv8 Large model for improved accuracy. This document details the complete workflow from environment setup, data preprocessing, exploratory data analysis, model training, to final prediction, with all processes optimized for GPU execution.
\end{abstract}

\tableofcontents
\newpage

\section{Introduction}

\subsection{Project Context}
The project was initiated as a computer vision assignment requiring the development of a real-time object detection system using YOLO and GPU acceleration. While the initial requirements were to implement a general object detection system, we recognized that configuring CUDA and importing a pre-trained YOLO model would be relatively straightforward. To demonstrate deeper understanding and practical application, we decided to fine-tune the model for a specific, challenging task: recognizing a specific car (Omar's car) among many vehicles in various environments.

\subsection{Objectives}
\begin{itemize}
    \item Configure CUDA environment for GPU acceleration
    \item Set up PyTorch with CUDA support
    \item Implement data preprocessing pipeline using Label Studio
    \item Perform exploratory data analysis on the dataset
    \item Fine-tune YOLOv8 model for specific car recognition
    \item Optimize all processes for GPU execution
    \item Evaluate model performance and demonstrate real-time detection
\end{itemize}

\subsection{Project Structure}
The project is organized as follows:
\begin{itemize}
    \item \texttt{data/}: Contains images, labels, and dataset configurations
    \item \texttt{notebooks/}: Jupyter notebooks for EDA, training, and prediction
    \item \texttt{models/}: Pre-trained model weights
    \item \texttt{src/}: Source code for training and inference
    \item \texttt{deployment/}: Deployment scripts
    \item \texttt{runs/}: Training outputs and results
\end{itemize}

\section{Environment Setup and CUDA Configuration}

\subsection{Hardware Requirements}
The project requires an NVIDIA GPU with CUDA support. Our setup utilized:
\begin{itemize}
    \item GPU: NVIDIA GeForce RTX 3060 Laptop GPU
    \item GPU Memory: 6GB VRAM
    \item CUDA Compute Capability: 8.6
\end{itemize}

\subsection{CUDA Installation}
\subsubsection{Downloading CUDA Toolkit}
CUDA Toolkit 12.6 was downloaded from the official NVIDIA website\footnote{\url{https://developer.nvidia.com/cuda-downloads}}. The installation process involved:

\begin{enumerate}
    \item Selecting the appropriate version (Windows 10/11, x86\_64)
    \item Downloading the installer (approximately 3GB)
    \item Running the installer and following the setup wizard
    \item Verifying installation using \texttt{nvcc --version}
\end{enumerate}

\subsubsection{cuDNN Installation}
cuDNN (CUDA Deep Neural Network library) is essential for deep learning operations:

\begin{enumerate}
    \item Downloaded cuDNN from NVIDIA Developer website\footnote{\url{https://developer.nvidia.com/cudnn}}
    \item Extracted the archive containing:
    \begin{itemize}
        \item \texttt{bin/cudnn64\_8.dll}
        \item \texttt{include/cudnn.h}
        \item \texttt{lib/cudnn.lib}
    \end{itemize}
    \item Copied files to CUDA installation directory:
    \begin{lstlisting}[language=bash]
    C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6\
    \end{lstlisting}
\end{enumerate}

\subsubsection{Environment Variables Configuration}
Critical environment variables were added to the system PATH:

\begin{lstlisting}[language=bash]
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6
CUDA_PATH_V12_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6
Path additions:
  - %CUDA_PATH%\bin
  - %CUDA_PATH%\libnvvp
  - %CUDA_PATH%\extras\CUPTI\lib64
\end{lstlisting}

Verification was performed using:
\begin{lstlisting}[language=Python]
import torch
print(torch.cuda.is_available())  # Should return True
print(torch.cuda.get_device_name(0))  # GPU name
print(torch.version.cuda)  # CUDA version
\end{lstlisting}

\subsection{PyTorch Installation with CUDA Support}
PyTorch was installed with CUDA 12.6 support using pip:

\begin{lstlisting}[language=bash]
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
\end{lstlisting}

The installation was verified:
\begin{lstlisting}[language=Python]
import torch
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")
print(f"cuDNN version: {torch.backends.cudnn.version()}")
print(f"GPU: {torch.cuda.get_device_name(0)}")
print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
\end{lstlisting}

Output:
\begin{verbatim}
PyTorch version: 2.9.0+cu126
CUDA available: True
CUDA version: 12.6
cuDNN version: 8902
GPU: NVIDIA GeForce RTX 3060 Laptop GPU
GPU Memory: 6.14 GB
\end{verbatim}

\subsection{Ultralytics YOLO Installation}
The Ultralytics YOLO library was installed for YOLOv8:

\begin{lstlisting}[language=bash]
pip install ultralytics
\end{lstlisting}

\section{Data Collection and Preprocessing}

\subsection{Data Collection}
A dataset of 184 images was collected, focusing on:
\begin{itemize}
    \item Various angles and perspectives of the target car
    \item Different lighting conditions
    \item Multiple backgrounds and environments
    \item Different distances and scales
\end{itemize}

\subsection{Label Studio Configuration}
Label Studio was configured locally for annotation:

\subsubsection{Installation}
\begin{lstlisting}[language=bash]
pip install label-studio
label-studio start
\end{lstlisting}

\subsubsection{Project Setup}
\begin{enumerate}
    \item Created a new project: "Omar Car Detection"
    \item Configured labeling interface for object detection
    \item Set up YOLO format export
    \item Imported all collected images
\end{enumerate}

\subsubsection{Labeling Interface Configuration}
The labeling interface was configured using XML:

\begin{lstlisting}[language=xml]
<View>
  <Image name="image" value="$image"/>
  <RectangleLabels name="label" toName="image">
    <Label value="omar_car" background="green"/>
  </RectangleLabels>
</View>
\end{lstlisting}

\subsection{Annotation Process}
\begin{itemize}
    \item Each image was manually annotated with bounding boxes
    \item Only the target car (Omar's car) was labeled
    \item Bounding boxes were drawn tightly around the car
    \item Quality checks were performed to ensure accuracy
\end{itemize}

\subsection{YOLO Format Export}
Labels were exported in YOLO format, where each label file contains:
\begin{itemize}
    \item Class ID (0 for omar\_car)
    \item Normalized bounding box coordinates (x\_center, y\_center, width, height)
\end{itemize}

Example label file (\texttt{image001.txt}):
\begin{verbatim}
0 0.5 0.5 0.3 0.4
\end{verbatim}

The dataset structure:
\begin{lstlisting}
data/
├── images/
│   ├── image001.jpg
│   ├── image002.jpg
│   └── ...
├── labels/
│   ├── image001.txt
│   ├── image002.txt
│   └── ...
└── classes.txt
    └── omar_car
\end{lstlisting}

\section{Exploratory Data Analysis (EDA)}

\subsection{Dataset Overview}
The dataset consisted of:
\begin{itemize}
    \item Total images: 184
    \item Labeled images: 184 (100\% coverage)
    \item Total bounding boxes: 184
    \item Class: omar\_car (single class)
\end{itemize}

\subsection{Image Analysis}
\subsubsection{Image Dimensions}
Analysis of image dimensions revealed:
\begin{itemize}
    \item Various resolutions (ranging from 320x240 to 1920x1080)
    \item Aspect ratios predominantly 16:9 and 4:3
    \item Most images in JPEG format
\end{itemize}

\subsubsection{Bounding Box Analysis}
\begin{itemize}
    \item Average bounding box area: Analyzed normalized coordinates
    \item Size distribution: Small (area < 0.02), Medium (0.02-0.15), Large (>0.15)
    \item Aspect ratio distribution: Most boxes have aspect ratios between 1.5 and 2.5
\end{itemize}

\subsection{Data Split}
The dataset was split into:
\begin{itemize}
    \item Training set: 148 images (80\%)
    \item Validation set: 36 images (20\%)
\end{itemize}

Random splitting was performed with a seed for reproducibility.

\subsection{Visualization}
Sample images with bounding boxes were visualized to ensure annotation quality and dataset diversity.

\section{Model Architecture and Training}

\subsection{YOLOv8 Architecture}
We utilized YOLOv8 Large (yolov8l.pt) for improved accuracy:
\begin{itemize}
    \item Parameters: ~43.7M
    \item Input size: 768x768 pixels
    \item Backbone: CSPDarknet53
    \item Neck: PANet
    \item Head: Decoupled head
\end{itemize}

\subsection{Training Configuration}
\subsubsection{Hyperparameters}
\begin{itemize}
    \item Epochs: 30 (10 frozen + 20 unfrozen)
    \item Batch size: 4 (adjusted for 6GB GPU memory)
    \item Image size: 768x768
    \item Learning rate: 0.005 (Phase 1), 0.003 (Phase 2)
    \item Optimizer: AdamW
    \item Mixed precision: Enabled (AMP)
\end{itemize}

\subsubsection{Data Augmentation}
Extensive data augmentation was applied:

\begin{itemize}
    \item HSV augmentation: Hue (0.02), Saturation (0.8), Value (0.5)
    \item Geometric transformations:
    \begin{itemize}
        \item Rotation: ±10 degrees
        \item Translation: ±15\%
        \item Scale: 0.4-1.0
        \item Shear: ±3 degrees
        \item Perspective: 0.0005
    \end{itemize}
    \item Flip: Horizontal (50\%), Vertical (10\%)
    \item Advanced augmentations:
    \begin{itemize}
        \item Mosaic: 80\% (Phase 1), 60\% (Phase 2)
        \item Mixup: 20\% (Phase 1), 10\% (Phase 2)
        \item Copy-paste: 10\% (Phase 1), 5\% (Phase 2)
    \end{itemize}
\end{itemize}

\subsection{Two-Phase Training Strategy}
\subsubsection{Phase 1: Frozen Backbone (10 epochs)}
\begin{itemize}
    \item First 10 layers frozen
    \item Stronger augmentations
    \item Learning rate: 0.005
    \item Focus: Learning object-specific features
\end{itemize}

\subsubsection{Phase 2: Fine-tuning (20 epochs)}
\begin{itemize}
    \item All layers unfrozen
    \item Reduced augmentations
    \item Learning rate: 0.003
    \item Focus: Fine-tuning all features
\end{itemize}

\subsection{GPU Utilization}
All training was performed on GPU:
\begin{itemize}
    \item Device: CUDA:0
    \item Memory usage: ~4.5GB / 6GB
    \item Batch size automatically adjusted based on GPU memory
    \item Mixed precision training for memory efficiency
\end{itemize}

Training code snippet:
\begin{lstlisting}[language=Python]
import torch
from ultralytics import YOLO

device = 0 if torch.cuda.is_available() else 'cpu'
model = YOLO('yolov8l.pt')

model.train(
    data='data/car.yaml',
    epochs=10,
    imgsz=768,
    batch=4,
    device=device,
    amp=True,  # Mixed precision
    freeze=10,  # Phase 1
    # ... augmentation parameters
)
\end{lstlisting}

\subsection{Training Metrics}
\subsubsection{Loss Curves}
Training showed steady convergence over 30 epochs:
\begin{itemize}
    \item Box loss: Decreased from 2.49 (epoch 1) to 0.30 (final)
    \item Class loss: Decreased from 2.44 (epoch 1) to 0.10 (final)
    \item DFL loss: Decreased from 2.99 (epoch 1) to 0.50 (final)
\end{itemize}

The training progress can be observed in the loss curves, showing consistent improvement throughout both phases. Phase 1 (frozen backbone) established a good foundation, while Phase 2 (unfrozen) fine-tuned the model for optimal performance.

\subsubsection{Validation Metrics}
Final validation results:
\begin{itemize}
    \item Precision: 0.998
    \item Recall: 0.972
    \item mAP@0.5: 0.988
    \item mAP@0.5:0.95: 0.809
\end{itemize}

\subsubsection{Performance Metrics}
\begin{itemize}
    \item Training time: ~2.5 hours (30 epochs)
    \item Inference speed: ~50ms per image (GPU)
    \item Model size: ~87MB (best.pt)
\end{itemize}

\section{Prediction and Evaluation}

\subsection{Prediction Pipeline}
A two-stage prediction system was implemented:

\subsubsection{Stage 1: General Object Detection}
\begin{itemize}
    \item Model: YOLOv8n (general COCO classes)
    \item Purpose: Detect all objects including cars
    \item Output: Bounding boxes for all detected objects
\end{itemize}

\subsubsection{Stage 2: Car Classification}
\begin{itemize}
    \item Model: Fine-tuned YOLOv8 Large
    \item Purpose: Classify detected cars as "omar\_car" or "other"
    \item Process:
    \begin{enumerate}
        \item Crop car regions from general detection
        \item Resize to 768x768
        \item Classify using fine-tuned model
        \item Overlay results on original image
    \end{enumerate}
\end{itemize}

\subsection{Visualization}
Results were visualized with color-coded bounding boxes:
\begin{itemize}
    \item \textcolor{green}{Lime}: omar\_car (confidence score displayed)
    \item \textcolor{yellow}{Yellow}: Other cars
    \item \textcolor{cyan}{Cyan}: Other objects
\end{itemize}

\subsection{Test Results}
Evaluation on test set (8 images):
\begin{itemize}
    \item All omar\_car instances correctly identified
    \item False positives: 0
    \item False negatives: 0
    \item Average confidence: 0.85
\end{itemize}

\section{GPU Performance Analysis}

\subsection{Training Performance}
\begin{itemize}
    \item GPU utilization: 85-95\%
    \item Memory usage: 4.5GB / 6GB (75\%)
    \item Training speed: ~15 images/second
    \item Speedup vs CPU: ~8x faster
\end{itemize}

\subsection{Inference Performance}
\begin{itemize}
    \item Inference speed: ~50ms per image
    \item Batch inference: ~200ms for batch of 4
    \item Real-time capability: Yes (20 FPS)
    \item GPU memory during inference: ~2GB
\end{itemize}

\subsection{Optimization Techniques}
\begin{itemize}
    \item Mixed precision training (AMP): 30\% memory reduction
    \item Batch size optimization: Adjusted for available memory
    \item Image size optimization: 768x768 for balance
    \item CUDA kernels: Optimized for RTX 3060
\end{itemize}

\section{Results and Discussion}

\subsection{Model Performance}
The fine-tuned YOLOv8 Large model achieved excellent performance:
\begin{itemize}
    \item High precision (99.8\%) indicates minimal false positives
    \item High recall (97.2\%) indicates minimal false negatives
    \item mAP@0.5 of 98.8\% demonstrates strong detection capability
    \item mAP@0.5:0.95 of 80.9\% shows robustness across IoU thresholds
\end{itemize}

\subsection{Challenges and Solutions}
\subsubsection{Challenge 1: Limited Dataset}
\begin{itemize}
    \item Problem: Only 184 images for training
    \item Solution: Extensive data augmentation and two-phase training
\end{itemize}

\subsubsection{Challenge 2: GPU Memory Constraints}
\begin{itemize}
    \item Problem: 6GB GPU memory with large model
    \item Solution: Mixed precision training and batch size optimization
\end{itemize}

\subsubsection{Challenge 3: Class Imbalance}
\begin{itemize}
    \item Problem: Single class (omar\_car) detection
    \item Solution: Strong augmentation and careful validation split
\end{itemize}

\subsection{Limitations}
\begin{itemize}
    \item Dataset size: Could benefit from more diverse images
    \item Generalization: Model may struggle with unseen car models
    \item Real-time performance: Could be improved with model quantization
\end{itemize}

\section{Conclusion}

This project successfully developed a real-time object detection system using YOLO and GPU acceleration. The system was fine-tuned to recognize a specific car among many vehicles, achieving high accuracy (98.8\% mAP@0.5) and real-time performance (20 FPS). Key achievements include:

\begin{itemize}
    \item Successful CUDA configuration and GPU utilization
    \item Comprehensive data preprocessing pipeline using Label Studio
    \item Effective fine-tuning strategy with two-phase training
    \item Excellent model performance with high precision and recall
    \item Real-time inference capability
\end{itemize}

The project demonstrates practical application of deep learning for computer vision, GPU acceleration, and model fine-tuning for specific use cases.

\section{Future Work}
\begin{itemize}
    \item Expand dataset with more diverse images
    \item Implement model quantization for faster inference
    \item Deploy model for real-time video processing
    \item Extend to multiple car recognition
    \item Implement tracking for video sequences
\end{itemize}

\section{Installation and Setup Instructions}

\subsection{Step-by-Step CUDA Installation}
\subsubsection{Step 1: Verify GPU Compatibility}
\begin{enumerate}
    \item Check NVIDIA GPU model: \texttt{nvidia-smi}
    \item Verify CUDA Compute Capability (minimum 3.5)
    \item Ensure sufficient GPU memory (minimum 4GB recommended)
\end{enumerate}

\subsubsection{Step 2: Download CUDA Toolkit}
\begin{enumerate}
    \item Visit \url{https://developer.nvidia.com/cuda-downloads}
    \item Select: Windows → x86\_64 → 10/11 → exe (local)
    \item Download CUDA Toolkit 12.6 (approximately 3GB)
    \item Run the installer as administrator
    \item Choose "Express Installation" for default settings
    \item Verify installation: \texttt{nvcc --version}
\end{enumerate}

\subsubsection{Step 3: Install cuDNN}
\begin{enumerate}
    \item Create NVIDIA Developer account
    \item Visit \url{https://developer.nvidia.com/cudnn}
    \item Download cuDNN v8.9.2 for CUDA 12.x
    \item Extract the ZIP file
    \item Copy files to CUDA directory:
    \begin{lstlisting}[language=bash]
    Copy bin\*.dll to C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6\bin
    Copy include\*.h to C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6\include
    Copy lib\*.lib to C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6\lib
    \end{lstlisting}
\end{enumerate}

\subsubsection{Step 4: Configure Environment Variables}
Add the following to System Environment Variables (PATH):
\begin{lstlisting}[language=bash]
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6\bin
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6\libnvvp
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6\extras\CUPTI\lib64
\end{lstlisting}

Create new environment variables:
\begin{lstlisting}[language=bash]
CUDA_PATH = C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6
CUDA_PATH_V12_6 = C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6
\end{lstlisting}

\subsubsection{Step 5: Verify Installation}
Test CUDA installation:
\begin{lstlisting}[language=bash]
nvcc --version
nvidia-smi
\end{lstlisting}

\subsection{PyTorch Installation}
Install PyTorch with CUDA 12.6 support:
\begin{lstlisting}[language=bash]
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
\end{lstlisting}

Verify PyTorch CUDA:
\begin{lstlisting}[language=Python]
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")
print(f"GPU: {torch.cuda.get_device_name(0)}")
\end{lstlisting}

\subsection{Label Studio Installation}
Install and configure Label Studio:
\begin{lstlisting}[language=bash]
pip install label-studio
label-studio start
\end{lstlisting}

Access Label Studio at \url{http://localhost:8080}

\section{Acknowledgments}
We would like to thank the professor for providing the project framework and guidance throughout the development process.

\newpage
\section{Appendix}

\subsection{A: Dataset Statistics}
\begin{table}[H]
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Metric} & \textbf{Value} \\
\hline
Total Images & 184 \\
Training Images & 148 \\
Validation Images & 36 \\
Total Bounding Boxes & 184 \\
Average Box Area & 0.15 \\
Image Formats & JPEG, PNG, WEBP \\
\hline
\end{tabular}
\caption{Dataset Statistics}
\end{table}

\subsection{B: Training Configuration}
\begin{table}[H]
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Parameter} & \textbf{Value} \\
\hline
Model & YOLOv8 Large \\
Input Size & 768x768 \\
Batch Size & 4 \\
Epochs (Phase 1) & 10 \\
Epochs (Phase 2) & 20 \\
Learning Rate (Phase 1) & 0.005 \\
Learning Rate (Phase 2) & 0.003 \\
Optimizer & AdamW \\
Mixed Precision & Yes \\
\hline
\end{tabular}
\caption{Training Configuration}
\end{table}

\subsection{C: Final Model Metrics}
\begin{table}[H]
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Metric} & \textbf{Value} \\
\hline
Precision & 0.998 \\
Recall & 0.972 \\
mAP@0.5 & 0.988 \\
mAP@0.5:0.95 & 0.809 \\
Model Size & 87 MB \\
Inference Speed & 50 ms/image \\
\hline
\end{tabular}
\caption{Final Model Performance}
\end{table}

\end{document}

